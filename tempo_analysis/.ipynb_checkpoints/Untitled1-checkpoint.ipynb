{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27671987-52af-44ff-a55a-a85fc0c277b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, '/home/jupyter/')\n",
    "from hourly_pollution_prediction.process_and_join.bbox import * \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "#for image inpainting\n",
    "from skimage import data\n",
    "from skimage.morphology import disk, binary_dilation\n",
    "from skimage.restoration import inpaint\n",
    "import cv2 as cv\n",
    "import xesmf as xe\n",
    "import geopandas as gpd\n",
    "import rioxarray\n",
    "from rioxarray.merge import merge_arrays\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35a41037-8d22-43e3-b758-e668655a6b79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Step 3: Convert to xarray\u001b[39;00m\n\u001b[1;32m     45\u001b[0m ds2 \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mto_xarray()\n\u001b[0;32m---> 46\u001b[0m ds2 \u001b[38;5;241m=\u001b[39m ds2\u001b[38;5;241m.\u001b[39mrename(\u001b[43m{\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mds2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_vars\u001b[49m\u001b[43m}\u001b[49m)\n\u001b[1;32m     47\u001b[0m ds2\u001b[38;5;241m.\u001b[39mto_netcdf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/gridded_census_data/ds_income.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 46\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Step 3: Convert to xarray\u001b[39;00m\n\u001b[1;32m     45\u001b[0m ds2 \u001b[38;5;241m=\u001b[39m df2\u001b[38;5;241m.\u001b[39mto_xarray()\n\u001b[0;32m---> 46\u001b[0m ds2 \u001b[38;5;241m=\u001b[39m ds2\u001b[38;5;241m.\u001b[39mrename({var: \u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplace\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m ds2\u001b[38;5;241m.\u001b[39mdata_vars})\n\u001b[1;32m     47\u001b[0m ds2\u001b[38;5;241m.\u001b[39mto_netcdf(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/gridded_census_data/ds_income.nc\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'float' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "df = pd.read_parquet('../../data/gridded_census_data/gridded_eif_pop_ageracesex_2024.parquet')\n",
    "df = df[df['grid_lat'].astype(float)>=lat_min]\n",
    "df = df[df['grid_lat'].astype(float)<=lat_max]\n",
    "df = df[df['grid_lon'].astype(float)>=lon_min]\n",
    "df = df[df['grid_lon'].astype(float)<=lon_max]\n",
    "\n",
    "df['grid_lon']=df['grid_lon'].astype(float)\n",
    "df['grid_lat']=df['grid_lat'].astype(float)\n",
    "\n",
    "df = df.groupby(['grid_lon','grid_lat','race_ethnicity'])['n_noise'].sum().reset_index()\n",
    "\n",
    "# Step 2: Pivot to get 3D shape (lat, lon, race)\n",
    "df = df.pivot_table(\n",
    "    index=[\"grid_lat\", \"grid_lon\"],\n",
    "    columns=\"race_ethnicity\",\n",
    "    values=\"n_noise\",\n",
    "    aggfunc=\"mean\"  # or \"sum\" or \"first\" depending on how you want to handle duplicates\n",
    ")\n",
    "\n",
    "# Step 3: Convert to xarray\n",
    "ds = df.to_xarray()\n",
    "ds = ds.rename({var: var.replace(\"/\", \"_\") for var in ds.data_vars})\n",
    "ds.to_netcdf('../../data/gridded_census_data/ds_race.nc')\n",
    "\n",
    "df2 = pd.read_parquet('../../data/gridded_census_data/gridded_eif_pop_raceincome_2024.parquet')\n",
    "df2 = df2[df2['grid_lat'].astype(float)>=lat_min]\n",
    "df2 = df2[df2['grid_lat'].astype(float)<=lat_max]\n",
    "df2 = df2[df2['grid_lon'].astype(float)>=lon_min]\n",
    "df2 = df2[df2['grid_lon'].astype(float)<=lon_max]\n",
    "\n",
    "df2['grid_lon']=df2['grid_lon'].astype(float)\n",
    "df2['grid_lat']=df2['grid_lat'].astype(float)\n",
    "\n",
    "df2 = df2.groupby(['grid_lon','grid_lat','income_decile'])['n_noise'].sum().reset_index()\n",
    "\n",
    "# Step 2: Pivot to get 3D shape (lat, lon, race)\n",
    "df2 = df2.pivot_table(\n",
    "    index=[\"grid_lat\", \"grid_lon\"],\n",
    "    columns=\"income_decile\",\n",
    "    values=\"n_noise\",\n",
    "    aggfunc=\"mean\"  # or \"sum\" or \"first\" depending on how you want to handle duplicates\n",
    ")\n",
    "\n",
    "# Step 3: Convert to xarray\n",
    "ds2 = df2.to_xarray()\n",
    "# ds2 = ds2.rename({var: var.replace(\"/\", \"_\") for var in ds2.data_vars})\n",
    "ds2.to_netcdf('../../data/gridded_census_data/ds_income.nc')\n"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "ds_env",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python (ds_env) (Local)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
