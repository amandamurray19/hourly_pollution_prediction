{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c5a4b30-0351-4439-823e-43b09677b091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from bbox import * \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "#for image inpainting\n",
    "from skimage import data\n",
    "from skimage.morphology import disk, binary_dilation\n",
    "from skimage.restoration import inpaint\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "from skimage.restoration import inpaint\n",
    "import cv2\n",
    "import xesmf as xe\n",
    "from pykrige.ok import OrdinaryKriging\n",
    "from tqdm import tqdm\n",
    "#convert the NO2 units to 10^15 molec/cm^2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b272df6e-830a-4960-9efd-7fa461a6ebde",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ds_env/lib/python3.11/site-packages/xesmf/smm.py:131: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn('Input array is not C_CONTIGUOUS. ' 'Will affect performance.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  1.3340624085516226\n",
      "r2:  0.11332746474012623\n"
     ]
    }
   ],
   "source": [
    "variable_name = 'vertical_column_troposphere'\n",
    "\n",
    "###############################\n",
    "# Load the datasets\n",
    "###############################\n",
    "full_ds_nonull = xr.open_dataset('../../data/tempo_data/inpaint_experiments/no_nulls.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_nonull['time'].values, return_index=True)\n",
    "full_ds_nonull = full_ds_nonull.isel(time=index)\n",
    "# full_ds_nonull = full_ds_nonull.isel(time=slice(0, 50))\n",
    "full_ds_nonull[variable_name]=full_ds_nonull[variable_name]/1000000000000000\n",
    "\n",
    "full_ds_less1 = xr.open_dataset('../../data/tempo_data/inpaint_experiments/nulls_less1perc.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_less1['time'].values, return_index=True)\n",
    "full_ds_less1 = full_ds_less1.isel(time=index)\n",
    "full_ds_less1[variable_name]=full_ds_less1[variable_name]/1000000000000000\n",
    "\n",
    "variable_name = 'vertical_column_troposphere'  # Replace with the actual variable name\n",
    "nan_mask = full_ds_less1[variable_name].isnull()\n",
    "time_dimension_nonulls = full_ds_nonull['time']\n",
    "nan_mask = nan_mask.assign_coords(time=time_dimension_nonulls)\n",
    "full_ds_nonull[f\"{variable_name}_masked\"] = full_ds_nonull[variable_name].where(~nan_mask)\n",
    "\n",
    "###############################\n",
    "# Geos-CF\n",
    "###############################\n",
    "# Convert timestamps to pandas datetime\n",
    "timestamps_dt = pd.to_datetime(time_dimension_nonulls)\n",
    "# Get unique months\n",
    "unique_months = timestamps_dt.to_period('M')\n",
    "\n",
    "# Generate bottom-of-the-hour timestamps for each hour in the original array\n",
    "bottom_of_hour = {}\n",
    "for month in unique_months:\n",
    "    # Filter timestamps for the current month\n",
    "    month_timestamps = timestamps_dt[timestamps_dt.to_period('M') == month]\n",
    "    \n",
    "    # Get unique hours within the month\n",
    "    unique_hours = month_timestamps.floor('h').unique()\n",
    "    \n",
    "    # Generate bottom-of-the-hour timestamps for these hours\n",
    "    bottom_of_hour[str(month)] =  np.array(unique_hours, dtype='datetime64[ns]')\n",
    "# datetime_array = np.array(datetime_list, dtype='datetime64[ns]')\n",
    "\n",
    "times_actual = np.array(timestamps_dt, dtype='datetime64[ns]')\n",
    "times_rounded = np.array(timestamps_dt.floor('h'), dtype='datetime64[ns]')\n",
    "# Create the dictionary that maps rounded times to actual times\n",
    "time_mapping = dict(zip(times_rounded, times_actual))\n",
    "\n",
    "# List to store datasets\n",
    "ds_list = []\n",
    "\n",
    "# Loop through each month key\n",
    "for month_key in bottom_of_hour.keys():\n",
    "    datetime_array = bottom_of_hour[month_key]\n",
    "\n",
    "    # Open the dataset for the current month\n",
    "    ds = xr.open_dataset(f'../../data/geos_cf_data/geos_cf_{month_key}.nc', engine='netcdf4')\n",
    "\n",
    "    # Select data for the current datetime_array\n",
    "    ds = ds.sel(time=datetime_array)\n",
    "\n",
    "    # Extract the 'NO2' variable\n",
    "    ds_no2 = ds['TROPCOL_NO2']\n",
    "\n",
    "    # Apply the time mapping to the 'time' coordinate\n",
    "    mapped_times = [time_mapping.get(time, time) for time in ds_no2.coords['time'].values]\n",
    "\n",
    "    # Update the 'time' coordinate with the mapped times\n",
    "    ds_no2.coords['time'] = ('time', mapped_times)\n",
    "\n",
    "    # Append to the list\n",
    "    ds_list.append(ds_no2)\n",
    "\n",
    "# Concatenate all selected datasets along the 'time' dimension\n",
    "concatenated_ds = xr.concat(ds_list, dim='time')\n",
    "\n",
    "def regrid_dataset(input_ds, ds_out, method='bilinear'):\n",
    "    '''Function that takes in the data you want to regrid, as well as an xarray of the lat/long to regrid to, and returns the\n",
    "    regridded data'''\n",
    "    # input_ds = xr.open_dataset(input_data)\n",
    "    output_ds = ds_out\n",
    "    regridder = xe.Regridder(input_ds, ds_out, method)\n",
    "    regridded_data = regridder(input_ds, keep_attrs=True)\n",
    "    return regridded_data\n",
    "\n",
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"latitude\": ([\"latitude\"], full_ds_nonull.coords['latitude'].values),\n",
    "        \"longitude\": ([\"longitude\"], full_ds_nonull.coords['longitude'].values),\n",
    "    }\n",
    ")\n",
    "concatenated_ds = regrid_dataset(concatenated_ds, ds_out)\n",
    "\n",
    "full_ds_nonull['time'] = np.array(full_ds_nonull['time'].values, dtype='datetime64[ns]')\n",
    "full_ds_nonull = xr.merge([full_ds_nonull, concatenated_ds])\n",
    "full_ds_nonull[f\"{variable_name}_geos_cf_fill\"]=full_ds_nonull[f\"{variable_name}_masked\"].fillna(full_ds_nonull[f\"TROPCOL_NO2\"])\n",
    "\n",
    "nan_mask['time'] = np.array(nan_mask['time'].values, dtype='datetime64[ns]')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# # Extract original values (masked by nan_mask)\n",
    "original_values = full_ds_nonull.where(nan_mask)[variable_name].values\n",
    "original_flat = original_values[nan_mask.values]\n",
    "\n",
    "inpaint_values = full_ds_nonull[f\"{variable_name}_geos_cf_fill\"].values\n",
    "inpainted_flat = inpaint_values[nan_mask.values]\n",
    "\n",
    "mae = mean_absolute_error(original_flat, inpainted_flat)\n",
    "r2 = r2_score(original_flat, inpainted_flat)\n",
    "\n",
    "print(\"mae: \", mae)\n",
    "print(\"r2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c13c3fa5-a7c5-4407-9d92-8ace6ed213db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ds_env/lib/python3.11/site-packages/xesmf/smm.py:131: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn('Input array is not C_CONTIGUOUS. ' 'Will affect performance.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  1.4510752586758724\n",
      "r2:  0.0524055732950105\n"
     ]
    }
   ],
   "source": [
    "variable_name = 'vertical_column_troposphere'\n",
    "\n",
    "###############################\n",
    "# Load the datasets\n",
    "###############################\n",
    "full_ds_nonull = xr.open_dataset('../../data/tempo_data/inpaint_experiments/no_nulls.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_nonull['time'].values, return_index=True)\n",
    "full_ds_nonull = full_ds_nonull.isel(time=index)\n",
    "# full_ds_nonull = full_ds_nonull.isel(time=slice(50, 100))\n",
    "full_ds_nonull[variable_name]=full_ds_nonull[variable_name]/1000000000000000\n",
    "\n",
    "full_ds_less1 = xr.open_dataset('../../data/tempo_data/inpaint_experiments/nulls_less5perc.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_less1['time'].values, return_index=True)\n",
    "full_ds_less1 = full_ds_less1.isel(time=index)\n",
    "full_ds_less1[variable_name]=full_ds_less1[variable_name]/1000000000000000\n",
    "\n",
    "variable_name = 'vertical_column_troposphere'  # Replace with the actual variable name\n",
    "nan_mask = full_ds_less1[variable_name].isnull()\n",
    "time_dimension_nonulls = full_ds_nonull['time']\n",
    "nan_mask = nan_mask.assign_coords(time=time_dimension_nonulls)\n",
    "full_ds_nonull[f\"{variable_name}_masked\"] = full_ds_nonull[variable_name].where(~nan_mask)\n",
    "\n",
    "###############################\n",
    "# Geos-CF\n",
    "###############################\n",
    "# Convert timestamps to pandas datetime\n",
    "timestamps_dt = pd.to_datetime(time_dimension_nonulls)\n",
    "# Get unique months\n",
    "unique_months = timestamps_dt.to_period('M')\n",
    "\n",
    "# Generate bottom-of-the-hour timestamps for each hour in the original array\n",
    "bottom_of_hour = {}\n",
    "for month in unique_months:\n",
    "    # Filter timestamps for the current month\n",
    "    month_timestamps = timestamps_dt[timestamps_dt.to_period('M') == month]\n",
    "    \n",
    "    # Get unique hours within the month\n",
    "    unique_hours = month_timestamps.floor('h')\n",
    "    \n",
    "    # Generate bottom-of-the-hour timestamps for these hours\n",
    "    bottom_of_hour[str(month)] =  np.array(unique_hours, dtype='datetime64[ns]')\n",
    "# datetime_array = np.array(datetime_list, dtype='datetime64[ns]')\n",
    "\n",
    "times_actual = np.array(timestamps_dt, dtype='datetime64[ns]')\n",
    "times_rounded = np.array(timestamps_dt.floor('h'), dtype='datetime64[ns]')\n",
    "# Create the dictionary that maps rounded times to actual times\n",
    "time_mapping = dict(zip(times_rounded, times_actual))\n",
    "\n",
    "# List to store datasets\n",
    "ds_list = []\n",
    "\n",
    "# Loop through each month key\n",
    "for month_key in bottom_of_hour.keys():\n",
    "    datetime_array = bottom_of_hour[month_key]\n",
    "\n",
    "    # Open the dataset for the current month\n",
    "    ds = xr.open_dataset(f'../../data/geos_cf_data/geos_cf_{month_key}.nc', engine='netcdf4')\n",
    "\n",
    "    # Select data for the current datetime_array\n",
    "    ds = ds.sel(time=datetime_array)\n",
    "\n",
    "    # Extract the 'NO2' variable\n",
    "    ds_no2 = ds['TROPCOL_NO2']\n",
    "\n",
    "    # Apply the time mapping to the 'time' coordinate\n",
    "    # mapped_times = [time_mapping.get(time, time) for time in ds_no2.coords['time'].values]\n",
    "\n",
    "    # Update the 'time' coordinate with the mapped times\n",
    "    # ds_no2.coords['time'] = ('time', mapped_times)\n",
    "\n",
    "    # Append to the list\n",
    "    ds_list.append(ds_no2)\n",
    "\n",
    "# Concatenate all selected datasets along the 'time' dimension\n",
    "concatenated_ds = xr.concat(ds_list, dim='time')\n",
    "concatenated_ds = concatenated_ds.assign_coords(time=sorted(times_actual))\n",
    "\n",
    "def regrid_dataset(input_ds, ds_out, method='bilinear'):\n",
    "    '''Function that takes in the data you want to regrid, as well as an xarray of the lat/long to regrid to, and returns the\n",
    "    regridded data'''\n",
    "    # input_ds = xr.open_dataset(input_data)\n",
    "    output_ds = ds_out\n",
    "    regridder = xe.Regridder(input_ds, ds_out, method)\n",
    "    regridded_data = regridder(input_ds, keep_attrs=True)\n",
    "    return regridded_data\n",
    "\n",
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"latitude\": ([\"latitude\"], full_ds_nonull.coords['latitude'].values),\n",
    "        \"longitude\": ([\"longitude\"], full_ds_nonull.coords['longitude'].values),\n",
    "    }\n",
    ")\n",
    "concatenated_ds = regrid_dataset(concatenated_ds, ds_out)\n",
    "\n",
    "full_ds_nonull['time'] = np.array(full_ds_nonull['time'].values, dtype='datetime64[ns]')\n",
    "full_ds_nonull = xr.merge([full_ds_nonull, concatenated_ds])\n",
    "full_ds_nonull[f\"{variable_name}_geos_cf_fill\"]=full_ds_nonull[f\"{variable_name}_masked\"].fillna(full_ds_nonull[f\"TROPCOL_NO2\"])\n",
    "\n",
    "nan_mask['time'] = np.array(nan_mask['time'].values, dtype='datetime64[ns]')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# # Extract original values (masked by nan_mask)\n",
    "original_values = full_ds_nonull.where(nan_mask)[variable_name].values\n",
    "original_flat = original_values[nan_mask.values]\n",
    "\n",
    "inpaint_values = full_ds_nonull[f\"{variable_name}_geos_cf_fill\"].values\n",
    "inpainted_flat = inpaint_values[nan_mask.values]\n",
    "\n",
    "mae = mean_absolute_error(original_flat, inpainted_flat)\n",
    "r2 = r2_score(original_flat, inpainted_flat)\n",
    "\n",
    "print(\"mae: \", mae)\n",
    "print(\"r2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "081b92be-8a87-452a-a74d-1f06dc5c404f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ds_env/lib/python3.11/site-packages/xesmf/smm.py:131: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn('Input array is not C_CONTIGUOUS. ' 'Will affect performance.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  1.3630930523120253\n",
      "r2:  0.09510180531829182\n"
     ]
    }
   ],
   "source": [
    "variable_name = 'vertical_column_troposphere'\n",
    "\n",
    "###############################\n",
    "# Load the datasets\n",
    "###############################\n",
    "full_ds_nonull = xr.open_dataset('../../data/tempo_data/inpaint_experiments/no_nulls.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_nonull['time'].values, return_index=True)\n",
    "full_ds_nonull = full_ds_nonull.isel(time=index)\n",
    "# full_ds_nonull = full_ds_nonull.isel(time=slice(100, 150))\n",
    "full_ds_nonull[variable_name]=full_ds_nonull[variable_name]/1000000000000000\n",
    "\n",
    "full_ds_less1 = xr.open_dataset('../../data/tempo_data/inpaint_experiments/nulls_less10perc.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_less1['time'].values, return_index=True)\n",
    "full_ds_less1 = full_ds_less1.isel(time=index)\n",
    "full_ds_less1[variable_name]=full_ds_less1[variable_name]/1000000000000000\n",
    "\n",
    "variable_name = 'vertical_column_troposphere'  # Replace with the actual variable name\n",
    "nan_mask = full_ds_less1[variable_name].isnull()\n",
    "time_dimension_nonulls = full_ds_nonull['time']\n",
    "nan_mask = nan_mask.assign_coords(time=time_dimension_nonulls)\n",
    "full_ds_nonull[f\"{variable_name}_masked\"] = full_ds_nonull[variable_name].where(~nan_mask)\n",
    "\n",
    "###############################\n",
    "# Geos-CF\n",
    "###############################\n",
    "# Convert timestamps to pandas datetime\n",
    "timestamps_dt = pd.to_datetime(time_dimension_nonulls)\n",
    "# Get unique months\n",
    "unique_months = timestamps_dt.to_period('M')\n",
    "\n",
    "# Generate bottom-of-the-hour timestamps for each hour in the original array\n",
    "bottom_of_hour = {}\n",
    "for month in unique_months:\n",
    "    # Filter timestamps for the current month\n",
    "    month_timestamps = timestamps_dt[timestamps_dt.to_period('M') == month]\n",
    "    \n",
    "    # Get unique hours within the month\n",
    "    unique_hours = month_timestamps.floor('h')\n",
    "    \n",
    "    # Generate bottom-of-the-hour timestamps for these hours\n",
    "    bottom_of_hour[str(month)] =  np.array(unique_hours, dtype='datetime64[ns]')\n",
    "# datetime_array = np.array(datetime_list, dtype='datetime64[ns]')\n",
    "\n",
    "times_actual = np.array(timestamps_dt, dtype='datetime64[ns]')\n",
    "times_rounded = np.array(timestamps_dt.floor('h'), dtype='datetime64[ns]')\n",
    "# Create the dictionary that maps rounded times to actual times\n",
    "time_mapping = dict(zip(times_rounded, times_actual))\n",
    "\n",
    "# List to store datasets\n",
    "ds_list = []\n",
    "\n",
    "# Loop through each month key\n",
    "for month_key in bottom_of_hour.keys():\n",
    "    datetime_array = bottom_of_hour[month_key]\n",
    "\n",
    "    # Open the dataset for the current month\n",
    "    ds = xr.open_dataset(f'../../data/geos_cf_data/geos_cf_{month_key}.nc', engine='netcdf4')\n",
    "\n",
    "    # Select data for the current datetime_array\n",
    "    ds = ds.sel(time=datetime_array)\n",
    "\n",
    "    # Extract the 'NO2' variable\n",
    "    ds_no2 = ds['TROPCOL_NO2']\n",
    "\n",
    "    # Apply the time mapping to the 'time' coordinate\n",
    "    # mapped_times = [time_mapping.get(time, time) for time in ds_no2.coords['time'].values]\n",
    "\n",
    "    # Update the 'time' coordinate with the mapped times\n",
    "    # ds_no2.coords['time'] = ('time', mapped_times)\n",
    "\n",
    "    # Append to the list\n",
    "    ds_list.append(ds_no2)\n",
    "\n",
    "# Concatenate all selected datasets along the 'time' dimension\n",
    "concatenated_ds = xr.concat(ds_list, dim='time')\n",
    "concatenated_ds = concatenated_ds.assign_coords(time=sorted(times_actual))\n",
    "\n",
    "def regrid_dataset(input_ds, ds_out, method='bilinear'):\n",
    "    '''Function that takes in the data you want to regrid, as well as an xarray of the lat/long to regrid to, and returns the\n",
    "    regridded data'''\n",
    "    # input_ds = xr.open_dataset(input_data)\n",
    "    output_ds = ds_out\n",
    "    regridder = xe.Regridder(input_ds, ds_out, method)\n",
    "    regridded_data = regridder(input_ds, keep_attrs=True)\n",
    "    return regridded_data\n",
    "\n",
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"latitude\": ([\"latitude\"], full_ds_nonull.coords['latitude'].values),\n",
    "        \"longitude\": ([\"longitude\"], full_ds_nonull.coords['longitude'].values),\n",
    "    }\n",
    ")\n",
    "concatenated_ds = regrid_dataset(concatenated_ds, ds_out)\n",
    "\n",
    "full_ds_nonull['time'] = np.array(full_ds_nonull['time'].values, dtype='datetime64[ns]')\n",
    "full_ds_nonull = xr.merge([full_ds_nonull, concatenated_ds])\n",
    "full_ds_nonull[f\"{variable_name}_geos_cf_fill\"]=full_ds_nonull[f\"{variable_name}_masked\"].fillna(full_ds_nonull[f\"TROPCOL_NO2\"])\n",
    "\n",
    "nan_mask['time'] = np.array(nan_mask['time'].values, dtype='datetime64[ns]')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# # Extract original values (masked by nan_mask)\n",
    "original_values = full_ds_nonull.where(nan_mask)[variable_name].values\n",
    "original_flat = original_values[nan_mask.values]\n",
    "\n",
    "inpaint_values = full_ds_nonull[f\"{variable_name}_geos_cf_fill\"].values\n",
    "inpainted_flat = inpaint_values[nan_mask.values]\n",
    "\n",
    "mae = mean_absolute_error(original_flat, inpainted_flat)\n",
    "r2 = r2_score(original_flat, inpainted_flat)\n",
    "\n",
    "print(\"mae: \", mae)\n",
    "print(\"r2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdeda1a6-bb5b-476a-93a0-5fe65e81c3ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ds_env/lib/python3.11/site-packages/xesmf/smm.py:131: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn('Input array is not C_CONTIGUOUS. ' 'Will affect performance.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  1.4860333766451692\n",
      "r2:  0.07266527960822511\n"
     ]
    }
   ],
   "source": [
    "variable_name = 'vertical_column_troposphere'\n",
    "\n",
    "###############################\n",
    "# Load the datasets\n",
    "###############################\n",
    "full_ds_nonull = xr.open_dataset('../../data/tempo_data/inpaint_experiments/no_nulls.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_nonull['time'].values, return_index=True)\n",
    "full_ds_nonull = full_ds_nonull.isel(time=index)\n",
    "# full_ds_nonull = full_ds_nonull.isel(time=slice(100, 150))\n",
    "full_ds_nonull[variable_name]=full_ds_nonull[variable_name]/1000000000000000\n",
    "\n",
    "full_ds_less1 = xr.open_dataset('../../data/tempo_data/inpaint_experiments/nulls_less25perc.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_less1['time'].values, return_index=True)\n",
    "full_ds_less1 = full_ds_less1.isel(time=index)\n",
    "full_ds_less1[variable_name]=full_ds_less1[variable_name]/1000000000000000\n",
    "\n",
    "variable_name = 'vertical_column_troposphere'  # Replace with the actual variable name\n",
    "nan_mask = full_ds_less1[variable_name].isnull()\n",
    "time_dimension_nonulls = full_ds_nonull['time']\n",
    "nan_mask = nan_mask.assign_coords(time=time_dimension_nonulls)\n",
    "full_ds_nonull[f\"{variable_name}_masked\"] = full_ds_nonull[variable_name].where(~nan_mask)\n",
    "\n",
    "###############################\n",
    "# Geos-CF\n",
    "###############################\n",
    "# Convert timestamps to pandas datetime\n",
    "timestamps_dt = pd.to_datetime(time_dimension_nonulls)\n",
    "# Get unique months\n",
    "unique_months = timestamps_dt.to_period('M')\n",
    "\n",
    "# Generate bottom-of-the-hour timestamps for each hour in the original array\n",
    "bottom_of_hour = {}\n",
    "for month in unique_months:\n",
    "    # Filter timestamps for the current month\n",
    "    month_timestamps = timestamps_dt[timestamps_dt.to_period('M') == month]\n",
    "    \n",
    "    # Get unique hours within the month\n",
    "    unique_hours = month_timestamps.floor('h')\n",
    "    \n",
    "    # Generate bottom-of-the-hour timestamps for these hours\n",
    "    bottom_of_hour[str(month)] =  np.array(unique_hours, dtype='datetime64[ns]')\n",
    "# datetime_array = np.array(datetime_list, dtype='datetime64[ns]')\n",
    "\n",
    "times_actual = np.array(timestamps_dt, dtype='datetime64[ns]')\n",
    "times_rounded = np.array(timestamps_dt.floor('h'), dtype='datetime64[ns]')\n",
    "# Create the dictionary that maps rounded times to actual times\n",
    "time_mapping = dict(zip(times_rounded, times_actual))\n",
    "\n",
    "# List to store datasets\n",
    "ds_list = []\n",
    "\n",
    "# Loop through each month key\n",
    "for month_key in bottom_of_hour.keys():\n",
    "    datetime_array = bottom_of_hour[month_key]\n",
    "\n",
    "    # Open the dataset for the current month\n",
    "    ds = xr.open_dataset(f'../../data/geos_cf_data/geos_cf_{month_key}.nc', engine='netcdf4')\n",
    "\n",
    "    # Select data for the current datetime_array\n",
    "    ds = ds.sel(time=datetime_array)\n",
    "\n",
    "    # Extract the 'NO2' variable\n",
    "    ds_no2 = ds['TROPCOL_NO2']\n",
    "\n",
    "    # Apply the time mapping to the 'time' coordinate\n",
    "    # mapped_times = [time_mapping.get(time, time) for time in ds_no2.coords['time'].values]\n",
    "\n",
    "    # Update the 'time' coordinate with the mapped times\n",
    "    # ds_no2.coords['time'] = ('time', mapped_times)\n",
    "\n",
    "    # Append to the list\n",
    "    ds_list.append(ds_no2)\n",
    "\n",
    "# Concatenate all selected datasets along the 'time' dimension\n",
    "concatenated_ds = xr.concat(ds_list, dim='time')\n",
    "concatenated_ds = concatenated_ds.assign_coords(time=sorted(times_actual))\n",
    "\n",
    "def regrid_dataset(input_ds, ds_out, method='bilinear'):\n",
    "    '''Function that takes in the data you want to regrid, as well as an xarray of the lat/long to regrid to, and returns the\n",
    "    regridded data'''\n",
    "    # input_ds = xr.open_dataset(input_data)\n",
    "    output_ds = ds_out\n",
    "    regridder = xe.Regridder(input_ds, ds_out, method)\n",
    "    regridded_data = regridder(input_ds, keep_attrs=True)\n",
    "    return regridded_data\n",
    "\n",
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"latitude\": ([\"latitude\"], full_ds_nonull.coords['latitude'].values),\n",
    "        \"longitude\": ([\"longitude\"], full_ds_nonull.coords['longitude'].values),\n",
    "    }\n",
    ")\n",
    "concatenated_ds = regrid_dataset(concatenated_ds, ds_out)\n",
    "\n",
    "full_ds_nonull['time'] = np.array(full_ds_nonull['time'].values, dtype='datetime64[ns]')\n",
    "full_ds_nonull = xr.merge([full_ds_nonull, concatenated_ds])\n",
    "full_ds_nonull[f\"{variable_name}_geos_cf_fill\"]=full_ds_nonull[f\"{variable_name}_masked\"].fillna(full_ds_nonull[f\"TROPCOL_NO2\"])\n",
    "\n",
    "nan_mask['time'] = np.array(nan_mask['time'].values, dtype='datetime64[ns]')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# # Extract original values (masked by nan_mask)\n",
    "original_values = full_ds_nonull.where(nan_mask)[variable_name].values\n",
    "original_flat = original_values[nan_mask.values]\n",
    "\n",
    "inpaint_values = full_ds_nonull[f\"{variable_name}_geos_cf_fill\"].values\n",
    "inpainted_flat = inpaint_values[nan_mask.values]\n",
    "\n",
    "mae = mean_absolute_error(original_flat, inpainted_flat)\n",
    "r2 = r2_score(original_flat, inpainted_flat)\n",
    "\n",
    "print(\"mae: \", mae)\n",
    "print(\"r2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "feac2b03-16d9-42af-a0bd-c03335d81f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ds_env/lib/python3.11/site-packages/xesmf/smm.py:131: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn('Input array is not C_CONTIGUOUS. ' 'Will affect performance.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  1.4058511680447383\n",
      "r2:  -0.006789968653210687\n"
     ]
    }
   ],
   "source": [
    "variable_name = 'vertical_column_troposphere'\n",
    "\n",
    "###############################\n",
    "# Load the datasets\n",
    "###############################\n",
    "full_ds_nonull = xr.open_dataset('../../data/tempo_data/inpaint_experiments/no_nulls.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_nonull['time'].values, return_index=True)\n",
    "full_ds_nonull = full_ds_nonull.isel(time=index)\n",
    "# full_ds_nonull = full_ds_nonull.isel(time=slice(150, 200))\n",
    "full_ds_nonull[variable_name]=full_ds_nonull[variable_name]/1000000000000000\n",
    "\n",
    "full_ds_less1 = xr.open_dataset('../../data/tempo_data/inpaint_experiments/nulls_less50perc.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_less1['time'].values, return_index=True)\n",
    "full_ds_less1 = full_ds_less1.isel(time=index)\n",
    "full_ds_less1[variable_name]=full_ds_less1[variable_name]/1000000000000000\n",
    "\n",
    "variable_name = 'vertical_column_troposphere'  # Replace with the actual variable name\n",
    "nan_mask = full_ds_less1[variable_name].isnull()\n",
    "time_dimension_nonulls = full_ds_nonull['time']\n",
    "nan_mask = nan_mask.assign_coords(time=time_dimension_nonulls)\n",
    "full_ds_nonull[f\"{variable_name}_masked\"] = full_ds_nonull[variable_name].where(~nan_mask)\n",
    "\n",
    "###############################\n",
    "# Geos-CF\n",
    "###############################\n",
    "# Convert timestamps to pandas datetime\n",
    "timestamps_dt = pd.to_datetime(time_dimension_nonulls)\n",
    "# Get unique months\n",
    "unique_months = timestamps_dt.to_period('M')\n",
    "\n",
    "# Generate bottom-of-the-hour timestamps for each hour in the original array\n",
    "bottom_of_hour = {}\n",
    "for month in unique_months:\n",
    "    # Filter timestamps for the current month\n",
    "    month_timestamps = timestamps_dt[timestamps_dt.to_period('M') == month]\n",
    "    \n",
    "    # Get unique hours within the month\n",
    "    unique_hours = month_timestamps.floor('h')\n",
    "    \n",
    "    # Generate bottom-of-the-hour timestamps for these hours\n",
    "    bottom_of_hour[str(month)] =  np.array(unique_hours, dtype='datetime64[ns]')\n",
    "# datetime_array = np.array(datetime_list, dtype='datetime64[ns]')\n",
    "\n",
    "times_actual = np.array(timestamps_dt, dtype='datetime64[ns]')\n",
    "times_rounded = np.array(timestamps_dt.floor('h'), dtype='datetime64[ns]')\n",
    "# Create the dictionary that maps rounded times to actual times\n",
    "time_mapping = dict(zip(times_rounded, times_actual))\n",
    "\n",
    "# List to store datasets\n",
    "ds_list = []\n",
    "\n",
    "# Loop through each month key\n",
    "for month_key in bottom_of_hour.keys():\n",
    "    datetime_array = bottom_of_hour[month_key]\n",
    "\n",
    "    # Open the dataset for the current month\n",
    "    ds = xr.open_dataset(f'../../data/geos_cf_data/geos_cf_{month_key}.nc', engine='netcdf4')\n",
    "\n",
    "    # Select data for the current datetime_array\n",
    "    ds = ds.sel(time=datetime_array)\n",
    "\n",
    "    # Extract the 'NO2' variable\n",
    "    ds_no2 = ds['TROPCOL_NO2']\n",
    "\n",
    "    # Apply the time mapping to the 'time' coordinate\n",
    "    # mapped_times = [time_mapping.get(time, time) for time in ds_no2.coords['time'].values]\n",
    "\n",
    "    # Update the 'time' coordinate with the mapped times\n",
    "    # ds_no2.coords['time'] = ('time', mapped_times)\n",
    "\n",
    "    # Append to the list\n",
    "    ds_list.append(ds_no2)\n",
    "\n",
    "# Concatenate all selected datasets along the 'time' dimension\n",
    "concatenated_ds = xr.concat(ds_list, dim='time')\n",
    "concatenated_ds = concatenated_ds.assign_coords(time=sorted(times_actual))\n",
    "\n",
    "def regrid_dataset(input_ds, ds_out, method='bilinear'):\n",
    "    '''Function that takes in the data you want to regrid, as well as an xarray of the lat/long to regrid to, and returns the\n",
    "    regridded data'''\n",
    "    # input_ds = xr.open_dataset(input_data)\n",
    "    output_ds = ds_out\n",
    "    regridder = xe.Regridder(input_ds, ds_out, method)\n",
    "    regridded_data = regridder(input_ds, keep_attrs=True)\n",
    "    return regridded_data\n",
    "\n",
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"latitude\": ([\"latitude\"], full_ds_nonull.coords['latitude'].values),\n",
    "        \"longitude\": ([\"longitude\"], full_ds_nonull.coords['longitude'].values),\n",
    "    }\n",
    ")\n",
    "concatenated_ds = regrid_dataset(concatenated_ds, ds_out)\n",
    "\n",
    "full_ds_nonull['time'] = np.array(full_ds_nonull['time'].values, dtype='datetime64[ns]')\n",
    "full_ds_nonull = xr.merge([full_ds_nonull, concatenated_ds])\n",
    "full_ds_nonull[f\"{variable_name}_geos_cf_fill\"]=full_ds_nonull[f\"{variable_name}_masked\"].fillna(full_ds_nonull[f\"TROPCOL_NO2\"])\n",
    "\n",
    "nan_mask['time'] = np.array(nan_mask['time'].values, dtype='datetime64[ns]')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# # Extract original values (masked by nan_mask)\n",
    "original_values = full_ds_nonull.where(nan_mask)[variable_name].values\n",
    "original_flat = original_values[nan_mask.values]\n",
    "\n",
    "inpaint_values = full_ds_nonull[f\"{variable_name}_geos_cf_fill\"].values\n",
    "inpainted_flat = inpaint_values[nan_mask.values]\n",
    "\n",
    "mae = mean_absolute_error(original_flat, inpainted_flat)\n",
    "r2 = r2_score(original_flat, inpainted_flat)\n",
    "\n",
    "print(\"mae: \", mae)\n",
    "print(\"r2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05395bec-4b36-492f-a9f2-fb09cac04f39",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/ds_env/lib/python3.11/site-packages/xesmf/smm.py:131: UserWarning: Input array is not C_CONTIGUOUS. Will affect performance.\n",
      "  warnings.warn('Input array is not C_CONTIGUOUS. ' 'Will affect performance.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae:  1.4833248088567077\n",
      "r2:  0.06481171975288813\n"
     ]
    }
   ],
   "source": [
    "variable_name = 'vertical_column_troposphere'\n",
    "\n",
    "###############################\n",
    "# Load the datasets\n",
    "###############################\n",
    "full_ds_nonull = xr.open_dataset('../../data/tempo_data/inpaint_experiments/no_nulls.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_nonull['time'].values, return_index=True)\n",
    "full_ds_nonull = full_ds_nonull.isel(time=index)\n",
    "# full_ds_nonull = full_ds_nonull.isel(time=slice(150, 200))\n",
    "full_ds_nonull[variable_name]=full_ds_nonull[variable_name]/1000000000000000\n",
    "\n",
    "full_ds_less1 = xr.open_dataset('../../data/tempo_data/inpaint_experiments/nulls_over50perc.nc', engine='netcdf4')\n",
    "unique_times, index = np.unique(full_ds_less1['time'].values, return_index=True)\n",
    "full_ds_less1 = full_ds_less1.isel(time=index)\n",
    "full_ds_less1[variable_name]=full_ds_less1[variable_name]/1000000000000000\n",
    "\n",
    "variable_name = 'vertical_column_troposphere'  # Replace with the actual variable name\n",
    "nan_mask = full_ds_less1[variable_name].isnull()\n",
    "time_dimension_nonulls = full_ds_nonull['time']\n",
    "nan_mask = nan_mask.assign_coords(time=time_dimension_nonulls)\n",
    "full_ds_nonull[f\"{variable_name}_masked\"] = full_ds_nonull[variable_name].where(~nan_mask)\n",
    "\n",
    "###############################\n",
    "# Geos-CF\n",
    "###############################\n",
    "# Convert timestamps to pandas datetime\n",
    "timestamps_dt = pd.to_datetime(time_dimension_nonulls)\n",
    "# Get unique months\n",
    "unique_months = timestamps_dt.to_period('M')\n",
    "\n",
    "# Generate bottom-of-the-hour timestamps for each hour in the original array\n",
    "bottom_of_hour = {}\n",
    "for month in unique_months:\n",
    "    # Filter timestamps for the current month\n",
    "    month_timestamps = timestamps_dt[timestamps_dt.to_period('M') == month]\n",
    "    \n",
    "    # Get unique hours within the month\n",
    "    unique_hours = month_timestamps.floor('h')\n",
    "    \n",
    "    # Generate bottom-of-the-hour timestamps for these hours\n",
    "    bottom_of_hour[str(month)] =  np.array(unique_hours, dtype='datetime64[ns]')\n",
    "# datetime_array = np.array(datetime_list, dtype='datetime64[ns]')\n",
    "\n",
    "times_actual = np.array(timestamps_dt, dtype='datetime64[ns]')\n",
    "times_rounded = np.array(timestamps_dt.floor('h'), dtype='datetime64[ns]')\n",
    "# Create the dictionary that maps rounded times to actual times\n",
    "time_mapping = dict(zip(times_rounded, times_actual))\n",
    "\n",
    "# List to store datasets\n",
    "ds_list = []\n",
    "\n",
    "# Loop through each month key\n",
    "for month_key in bottom_of_hour.keys():\n",
    "    datetime_array = bottom_of_hour[month_key]\n",
    "\n",
    "    # Open the dataset for the current month\n",
    "    ds = xr.open_dataset(f'../../data/geos_cf_data/geos_cf_{month_key}.nc', engine='netcdf4')\n",
    "\n",
    "    # Select data for the current datetime_array\n",
    "    ds = ds.sel(time=datetime_array)\n",
    "\n",
    "    # Extract the 'NO2' variable\n",
    "    ds_no2 = ds['TROPCOL_NO2']\n",
    "\n",
    "    # Apply the time mapping to the 'time' coordinate\n",
    "    # mapped_times = [time_mapping.get(time, time) for time in ds_no2.coords['time'].values]\n",
    "\n",
    "    # Update the 'time' coordinate with the mapped times\n",
    "    # ds_no2.coords['time'] = ('time', mapped_times)\n",
    "\n",
    "    # Append to the list\n",
    "    ds_list.append(ds_no2)\n",
    "\n",
    "# Concatenate all selected datasets along the 'time' dimension\n",
    "concatenated_ds = xr.concat(ds_list, dim='time')\n",
    "concatenated_ds = concatenated_ds.assign_coords(time=sorted(times_actual))\n",
    "\n",
    "def regrid_dataset(input_ds, ds_out, method='bilinear'):\n",
    "    '''Function that takes in the data you want to regrid, as well as an xarray of the lat/long to regrid to, and returns the\n",
    "    regridded data'''\n",
    "    # input_ds = xr.open_dataset(input_data)\n",
    "    output_ds = ds_out\n",
    "    regridder = xe.Regridder(input_ds, ds_out, method)\n",
    "    regridded_data = regridder(input_ds, keep_attrs=True)\n",
    "    return regridded_data\n",
    "\n",
    "ds_out = xr.Dataset(\n",
    "    {\n",
    "        \"latitude\": ([\"latitude\"], full_ds_nonull.coords['latitude'].values),\n",
    "        \"longitude\": ([\"longitude\"], full_ds_nonull.coords['longitude'].values),\n",
    "    }\n",
    ")\n",
    "concatenated_ds = regrid_dataset(concatenated_ds, ds_out)\n",
    "\n",
    "full_ds_nonull['time'] = np.array(full_ds_nonull['time'].values, dtype='datetime64[ns]')\n",
    "full_ds_nonull = xr.merge([full_ds_nonull, concatenated_ds])\n",
    "full_ds_nonull[f\"{variable_name}_geos_cf_fill\"]=full_ds_nonull[f\"{variable_name}_masked\"].fillna(full_ds_nonull[f\"TROPCOL_NO2\"])\n",
    "\n",
    "nan_mask['time'] = np.array(nan_mask['time'].values, dtype='datetime64[ns]')\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "# # Extract original values (masked by nan_mask)\n",
    "original_values = full_ds_nonull.where(nan_mask)[variable_name].values\n",
    "original_flat = original_values[nan_mask.values]\n",
    "\n",
    "inpaint_values = full_ds_nonull[f\"{variable_name}_geos_cf_fill\"].values\n",
    "inpainted_flat = inpaint_values[nan_mask.values]\n",
    "\n",
    "mae = mean_absolute_error(original_flat, inpainted_flat)\n",
    "r2 = r2_score(original_flat, inpainted_flat)\n",
    "\n",
    "print(\"mae: \", mae)\n",
    "print(\"r2: \", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "884dbfae-23c6-4718-97a4-954f566b3475",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(--jp-content-font-color0, rgba(0, 0, 0, 1));\n",
       "  --xr-font-color2: var(--jp-content-font-color2, rgba(0, 0, 0, 0.54));\n",
       "  --xr-font-color3: var(--jp-content-font-color3, rgba(0, 0, 0, 0.38));\n",
       "  --xr-border-color: var(--jp-border-color2, #e0e0e0);\n",
       "  --xr-disabled-color: var(--jp-layout-color3, #bdbdbd);\n",
       "  --xr-background-color: var(--jp-layout-color0, white);\n",
       "  --xr-background-color-row-even: var(--jp-layout-color1, white);\n",
       "  --xr-background-color-row-odd: var(--jp-layout-color2, #eeeeee);\n",
       "}\n",
       "\n",
       "html[theme=dark],\n",
       "html[data-theme=dark],\n",
       "body[data-theme=dark],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: rgba(255, 255, 255, 1);\n",
       "  --xr-font-color2: rgba(255, 255, 255, 0.54);\n",
       "  --xr-font-color3: rgba(255, 255, 255, 0.38);\n",
       "  --xr-border-color: #1F1F1F;\n",
       "  --xr-disabled-color: #515151;\n",
       "  --xr-background-color: #111111;\n",
       "  --xr-background-color-row-even: #111111;\n",
       "  --xr-background-color-row-odd: #313131;\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: '►';\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: '▼';\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: '(';\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: ')';\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: ',';\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  background-color: var(--xr-background-color) !important;\n",
       "  padding-bottom: 5px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;vertical_column_troposphere_geos_cf_fill&#x27; ()&gt; Size: 8B\n",
       "array(12720000)</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'vertical_column_troposphere_geos_cf_fill'</div></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-ef1f9a30-76e1-4063-a747-68884175d0a5' class='xr-array-in' type='checkbox' checked><label for='section-ef1f9a30-76e1-4063-a747-68884175d0a5' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>12720000</span></div><div class='xr-array-data'><pre>array(12720000)</pre></div></div></li><li class='xr-section-item'><input id='section-1410b17c-bdb4-4d8a-91d3-597e4342498b' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-1410b17c-bdb4-4d8a-91d3-597e4342498b' class='xr-section-summary'  title='Expand/collapse section'>Coordinates: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-4e9d8849-8867-4e91-8d4e-53d73f47a108' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-4e9d8849-8867-4e91-8d4e-53d73f47a108' class='xr-section-summary'  title='Expand/collapse section'>Indexes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'></ul></div></li><li class='xr-section-item'><input id='section-0f28872b-3948-4d77-93a5-f7011d1f1d27' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-0f28872b-3948-4d77-93a5-f7011d1f1d27' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'vertical_column_troposphere_geos_cf_fill' ()> Size: 8B\n",
       "array(12720000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_ds_nonull[f\"{variable_name}_geos_cf_fill\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b210fb-90cb-4239-af69-7feb92e417f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# # Define your latitude and longitude bounds\n",
    "# lat_min, lat_max = 28.6, 33.4  # Example latitude range\n",
    "# lon_min, lon_max = -98.9, -88.3  # Example longitude range\n",
    "\n",
    "# Select one hour of temperature data (e.g., the first timestamp)\n",
    "hour_index = 0 #Change this to select a different hour if desired\n",
    "temperature_data = full_ds_nonull[f\"{variable_name}_geos_cf_fill\"].isel(time=hour_index)\n",
    "# temperature_data = ds['Percent_Tree_Cover']\n",
    "\n",
    "# Plot the data with switched axes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot with latitude on x-axis and longitude on y-axis\n",
    "temperature_data.T.plot(\n",
    "    cmap=\"coolwarm\",  # Colormap for temperature visualization\n",
    "    cbar_kwargs={'label': 'Temperature (K)'}  # Add color bar label\n",
    ")\n",
    "\n",
    "# Update axis labels\n",
    "plt.xlabel(\"Latitude\")\n",
    "plt.ylabel(\"Longitude\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4616eeb6-9f6f-4b29-8c02-0342488e25ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5685458006039108"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3f995c1-9a9c-46ca-82f1-e7bd86553bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2284887116882628"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "ds_env",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python (ds_env) (Local)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
