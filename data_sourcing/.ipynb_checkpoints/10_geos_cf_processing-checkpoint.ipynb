{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2309f0a0-6f30-47a5-82b5-d658b137f78c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: conda init [-h] [--all] [--user] [--no-user] [--system] [--reverse]\n",
      "                  [--json] [-v] [-q] [-d]\n",
      "                  [SHELLS ...]\n",
      "conda init: error: argument SHELLS: invalid choice: 'activate' (choose from 'bash', 'fish', 'tcsh', 'xonsh', 'zsh', 'powershell')\n"
     ]
    }
   ],
   "source": [
    "import ee\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.array as da\n",
    "import xee\n",
    "from bbox import * \n",
    "from datetime import datetime\n",
    "\n",
    "# Trigger the authentication flow\n",
    "ee.Authenticate()\n",
    "\n",
    "# Initialize the Earth Engine library\n",
    "ee.Initialize(project='satellite-modeling')\n",
    "\n",
    "# Define the rectangle that encompasses Louisiana and Texas\n",
    "bbox = ee.Geometry.Rectangle([lon_min, lat_min, lon_max, lat_max])\n",
    "\n",
    "start_date = '2023-08-01T00:00'\n",
    "end_date = datetime.now().strftime('%Y-%m-%dT%H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15e6ef0-e82d-4070-91dc-e47a621b7cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e65f5352-e03e-4420-9633-93836627e5bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "no2_hours = pd.read_csv(\"../../data/tempo_data/no2_file_hours.csv\")\n",
    "no2_hours=list(no2_hours['time_hr_ct'])\n",
    "time_list = np.array(no2_hours, dtype=\"datetime64[ns]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9b96b6a-c5ea-445e-8014-601dd13ba0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Load NLDAS Data\n",
    "##################################################\n",
    "\n",
    "# List of climate variables to download from NLDAS\n",
    "variables =['temperature', 'specific_humidity', 'pressure', 'wind_u', 'wind_v', 'longwave_radiation', 'convective_fraction', 'potential_energy', 'potential_evaporation', 'total_precipitation', 'shortwave_radiation']\n",
    "\n",
    "# Load NLDAS hourly data and filter by region and date\n",
    "dataset = ee.ImageCollection(\"NASA/NLDAS/FORA0125_H002\") \\\n",
    "            .filterDate(start_date, end_date) \\\n",
    "            .filterBounds(bbox) \\\n",
    "            .select(variables)\n",
    "\n",
    "ds = xr.open_dataset(dataset, engine='ee', crs='EPSG:4326', scale=0.01)\n",
    "# Filter the dataset based on the latitude and longitude bounds\n",
    "ds = ds.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4218be4b-3e92-45a5-9c9c-e5fb1aca969d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Load NLDAS Data\n",
    "##################################################\n",
    "\n",
    "# List of climate variables to download from NLDAS\n",
    "variables =['temperature', 'specific_humidity', 'pressure', 'wind_u', 'wind_v', 'longwave_radiation', 'convective_fraction', 'potential_energy', 'potential_evaporation', 'total_precipitation', 'shortwave_radiation']\n",
    "\n",
    "# Load NLDAS hourly data and filter by region and date\n",
    "dataset = ee.ImageCollection(\"NASA/NLDAS/FORA0125_H002\") \\\n",
    "            .filterDate(start_date, end_date) \\\n",
    "            .filterBounds(bbox) \\\n",
    "            .select(variables)\n",
    "\n",
    "ds = xr.open_dataset(dataset, engine='ee', crs='EPSG:4326', scale=0.01)\n",
    "# Filter the dataset based on the latitude and longitude bounds\n",
    "ds = ds.sel(lat=slice(lat_min, lat_max), lon=slice(lon_min, lon_max))\n",
    "\n",
    "##################################################\n",
    "# Change Timestamps\n",
    "##################################################\n",
    "# Recreate UTC Time Stamps\n",
    "ds_time_list = ds[\"time\"].values.tolist()\n",
    "timestamps_utc = pd.to_datetime(ds_time_list)\n",
    "timestamps_utc = timestamps_utc.tz_localize('UTC')\n",
    "\n",
    "# Add 1 hour to each timestamp so that it contains weather data from prior hour\n",
    "timestamps_adjusted = timestamps_utc + pd.Timedelta(hours=1)\n",
    "\n",
    "# Convert to Central Time (handles daylight saving time automatically)\n",
    "timestamps_central = timestamps_adjusted.tz_convert('America/Chicago')\n",
    "timestamps_central = timestamps_central.tz_localize(None)\n",
    "timestamps_central=np.array(timestamps_central, dtype=\"datetime64[ns]\")\n",
    "# Replace the time dimension\n",
    "ds = ds.assign_coords(time=timestamps_central)\n",
    "\n",
    "# Remove duplicate hour from time change\n",
    "ds = ds.isel(time=ds.get_index(\"time\").duplicated() == False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d5b6ae7-def2-439a-a9f4-07b7fd64923f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find dates included in both sat and weather data\n",
    "seta = set(timestamps_central)\n",
    "setb = set(time_list)\n",
    "union_set = seta & setb\n",
    "full_time_list = list(union_set)\n",
    "filtered_ds = ds.sel(time=full_time_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0748a6-295e-40c6-b874-e75c5cf3d0fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask.diagnostics import ProgressBar\n",
    "\n",
    "# Convert to dask dataframe for chunking, stops to_netcdf from killing kernel\n",
    "ds_dask = filtered_ds.chunk({'time': 20}) \n",
    "\n",
    "# Use ProgressBar to show the progress\n",
    "with ProgressBar():\n",
    "    # Save the Dask-backed xarray to NetCDF in Google Cloud Storage\n",
    "    ds_dask.to_netcdf('../../data/weather_data/weather_data.nc', engine='h5netcdf')\n",
    "## Other option\n",
    "# ds_dask.to_zarr('../data/weather_data/weather_data.zarr', mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e718685e-3856-47b5-9461-274e181ac700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # Define your latitude and longitude bounds\n",
    "# lat_min, lat_max = 28.6, 33.4  # Example latitude range\n",
    "# lon_min, lon_max = -98.9, -88.3  # Example longitude range\n",
    "\n",
    "# # Select one hour of temperature data (e.g., the first timestamp)\n",
    "# hour_index = 1  # Change this to select a different hour if desired\n",
    "# temperature_data = ds['temperature'].isel(time=hour_index)\n",
    "\n",
    "# # Plot the data with switched axes\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Plot with latitude on x-axis and longitude on y-axis\n",
    "# temperature_data.T.plot(\n",
    "#     cmap=\"coolwarm\",  # Colormap for temperature visualization\n",
    "#     cbar_kwargs={'label': 'Temperature (K)'}  # Add color bar label\n",
    "# )\n",
    "\n",
    "# # Update axis labels\n",
    "# plt.xlabel(\"Latitude\")\n",
    "# plt.ylabel(\"Longitude\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "gee_env",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python (gee_env) (Local)",
   "language": "python",
   "name": "gee_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
