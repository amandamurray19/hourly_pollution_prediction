{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79e1fb91-dab6-4593-ba2f-8a2f0b14f398",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".netrc file does not exist.\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import xesmf as xe\n",
    "import xarray as xr\n",
    "import netCDF4\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import base64\n",
    "import boto3\n",
    "import json\n",
    "import requests\n",
    "import os\n",
    "import platform\n",
    "from subprocess import Popen\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import re\n",
    "import pandas as pd\n",
    "from load_credentials import *\n",
    "from bbox import * \n",
    "from netCDF4 import Dataset\n",
    "import netCDF4 as nc\n",
    "from bbox import * \n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define event with credentials and S3 endpoint details\n",
    "event = {\n",
    "    's3_endpoint': 'https://data.asdc.earthdata.nasa.gov/s3credentials',  # replace with actual endpoint\n",
    "    'edl_username': 'amanda.murray19',  # replace with your EDL username\n",
    "    'edl_password': 'Sat_modeling_berk2024',  # replace with your EDL password\n",
    "    'bucket_name': 'asdc-prod-protected/TEMPO/TEMPO_NO2_L3_V03'  # replace with your bucket name\n",
    "}\n",
    "\n",
    "netrc_path = os.path.expanduser('~/.netrc')  # Expands to the user's home directory\n",
    "if os.path.exists(netrc_path):\n",
    "    print(\".netrc file exists.\")\n",
    "    os.remove(netrc_path)\n",
    "    print(\".netrc file has been removed.\")\n",
    "else:\n",
    "    print(\".netrc file does not exist.\")# Retrieve credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98267084-81ec-4359-91a3-56e85fd29001",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../../data/tempo_data/o3_tempo_files_df.csv\")\n",
    "df['time_hr_ct'] = pd.to_datetime(df['timestamp_ct']).dt.floor('h')\n",
    "\n",
    "result_df = df.groupby(['date_central', 'Hour'], as_index=False).first()\n",
    "result_df['time_hr_ct'] = pd.to_datetime(result_df['timestamp_ct']).dt.floor('h')\n",
    "result_df[['time_hr_ct']].to_csv('../../data/tempo_data/no2_file_hours.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "847038b1-d599-4872-b4e1-097390f87648",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TIME 5 days = 875 s (~15 min)\n",
    "# Initialize the Google Cloud Storage client\n",
    "# Example DataFrame (assuming it exists)\n",
    "satellite_null_data = pd.DataFrame({\n",
    "    'date': [],\n",
    "    'file': [],\n",
    "    'time': [],\n",
    "    'null_count': [],\n",
    "    'percent_null': []\n",
    "})\n",
    "\n",
    "date_list = list(df['date_central'].unique())\n",
    "\n",
    "for date in date_list:\n",
    "    # Retrieve credentials\n",
    "    creds = retrieve_credentials(event)\n",
    "\n",
    "    # Use the credentials to access the S3 bucket\n",
    "    client = boto3.client('s3',\n",
    "        aws_access_key_id=creds[\"accessKeyId\"],\n",
    "        aws_secret_access_key=creds[\"secretAccessKey\"],\n",
    "        aws_session_token=creds[\"sessionToken\"]\n",
    "    )\n",
    "    \n",
    "    file_df = df[df['date_central']==date]\n",
    "    filepaths = list(file_df['FilePath'])\n",
    "    times = list(file_df['time_hr_ct'])\n",
    "    full_time = list(file_df['timestamp_ct'])\n",
    "    \n",
    "    daily_xr_list = []\n",
    "    \n",
    "    for i in range(len(filepaths)):\n",
    "        file=filepaths[i]\n",
    "        new_time = str(np.array(times[i]))\n",
    "        \n",
    "        bucket_name = 'asdc-prod-protected'\n",
    "        object_key = file\n",
    "        local_file_name = 'current_sat.nc'\n",
    "        client.download_file(bucket_name, object_key, local_file_name)\n",
    "        \n",
    "        tempo = xr.open_dataset('current_sat.nc', group=\"/product\")\n",
    "        lat_lon_coords = xr.open_dataset('current_sat.nc')\n",
    "        lat = lat_lon_coords.coords['latitude'].values\n",
    "        lon = lat_lon_coords.coords['longitude'].values\n",
    "        tempo = tempo.assign_coords(latitude=(\"latitude\", lat), longitude=(\"longitude\", lon), time=[new_time])\n",
    "        louisiana_data = tempo.sel(latitude=(tempo.latitude  >= lat_min) & (tempo.latitude <= lat_max))\n",
    "        louisiana_data = louisiana_data.sel(longitude=(tempo.longitude  >= lon_min) & (tempo.longitude <= lon_max))\n",
    "        del tempo\n",
    "        del lat\n",
    "        del lon\n",
    "        \n",
    "        lat_new = np.arange(lat_min+0.005, lat_max, 0.01)\n",
    "        lon_new = np.arange(lon_min+0.005, lon_max, 0.01)\n",
    "\n",
    "        ds_out = xr.Dataset(\n",
    "            {\n",
    "                \"lat\": ([\"lat\"], lat_new),\n",
    "                \"lon\": ([\"lon\"], lon_new),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Create the regridder object.\n",
    "        regridder = xe.Regridder(louisiana_data, ds_out, \"bilinear\")\n",
    "\n",
    "        # Apply the regridding operation.\n",
    "        louisiana_data_regrid = regridder(louisiana_data)\n",
    "        daily_xr_list.append(louisiana_data_regrid)\n",
    "        \n",
    "        null_count = int(louisiana_data_regrid.column_amount_o3.isnull().sum().values)\n",
    "        total_elements = louisiana_data_regrid.column_amount_o3.size\n",
    "        nan_percentage = round((null_count / total_elements) * 100,0)\n",
    "        \n",
    "        new_row = {'date':date, 'file':file, 'time':new_time, 'real_time':full_time, 'null_count':null_count, 'percent_null':nan_percentage}\n",
    "        # Convert the new row to a DataFrame\n",
    "        new_row_df = pd.DataFrame([new_row])\n",
    "        # Append the new row to the DataFrame using concat\n",
    "        satellite_null_data = pd.concat([satellite_null_data, new_row_df], ignore_index=True)\n",
    "        \n",
    "    combined_data = xr.concat(daily_xr_list, dim='time')\n",
    "    \n",
    "    combined_data.to_netcdf(f'../../data/tempo_data/o3_daily_files/tempo_o3_{date}.nc')\n",
    "         \n",
    "\n",
    "satellite_null_data.to_csv(\"../../data/tempo_data/o3_null_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d91a5413-3bd6-4103-b496-67b3821e1c31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# # # Define your latitude and longitude bounds\n",
    "# # lat_min, lat_max = 28.6, 33.4  # Example latitude range\n",
    "# # lon_min, lon_max = -98.9, -88.3  # Example longitude range\n",
    "\n",
    "# # Select one hour of temperature data (e.g., the first timestamp)\n",
    "# # hour_index = 1  # Change this to select a different hour if desired\n",
    "# temperature_data = louisiana_data['uv_aerosol_index']\n",
    "# # temperature_data = ds['Percent_Tree_Cover']\n",
    "\n",
    "# # Plot the data with switched axes\n",
    "# plt.figure(figsize=(10, 6))\n",
    "\n",
    "# # Plot with latitude on x-axis and longitude on y-axis\n",
    "# temperature_data.T.plot(\n",
    "#     cmap=\"coolwarm\",  # Colormap for temperature visualization\n",
    "#     cbar_kwargs={'label': 'Temperature (K)'}  # Add color bar label\n",
    "# )\n",
    "\n",
    "# # Update axis labels\n",
    "# plt.xlabel(\"Latitude\")\n",
    "# plt.ylabel(\"Longitude\")\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "ds_env",
   "name": "workbench-notebooks.m125",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m125"
  },
  "kernelspec": {
   "display_name": "Python (ds_env) (Local)",
   "language": "python",
   "name": "ds_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
